{"rule_id":"word_length_fibonacci_claude_084","model":"claude-haiku-4-5-20251001","few_shot_count":100,"prompt_variation":"simple","ground_truth_articulation":"The word lengths in the text follow the Fibonacci sequence (1, 1, 2, 3, 5, 8, etc.) for at least the first 5 words.","generated_articulation":"# Rule\n\nThe output is **True** if the input contains at least 3 tokens that appear to be random character sequences (gibberish strings of 3+ characters like \"wpus\", \"emfkb\", \"rxcka\"), and **False** if the input contains mostly common English words (like \"python\", \"function\", \"test\", \"hello\", \"world\", etc.) or has repeated words.","raw_response":"# Rule\n\nThe output is **True** if the input contains at least 3 tokens that appear to be random character sequences (gibberish strings of 3+ characters like \"wpus\", \"emfkb\", \"rxcka\"), and **False** if the input contains mostly common English words (like \"python\", \"function\", \"test\", \"hello\", \"world\", etc.) or has repeated words.","keyword_match_score":0.5555555555555556,"rouge_l_score":0.16216216216216217,"llm_judge_score":0.1,"llm_judge_reasoning":"The ground truth rule focuses on the pattern of word lengths following the Fibonacci sequence, which is a specific structural property of the text. In contrast, the generated rule classifies based on the presence of gibberish tokens versus common English words, which is a different type of pattern detection. They do not identify the same key features; one is about numerical word length patterns, the other about token randomness and vocabulary. Consequently, they would rarely produce the same classification on the same input, as their core concepts are fundamentally different.","functional_test_accuracy":0.76,"functional_test_details":{"n_total":50,"n_classified":50,"n_correct":38,"n_skipped":0,"accuracy":0.76},"parse_error":false}
