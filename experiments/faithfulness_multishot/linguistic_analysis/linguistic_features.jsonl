{"rule_id": "reference_negation_presence", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "I need to find the pattern that distinguishes True from False classifications.\n\nLet me analyze the examples systematically by looking for common words or patterns in True vs False cases.\n\n**Analyzing True cases:**\n- \"test value function won't example\" - contains \"won't\"\n- \"no jumps function example the world\" - contains \"no\"\n- \"sample world result the code no\" - contains \"no\"\n- \"testing python no world\" - contains \"no\"\n- \"code no input code\" - contains \"no\"\n- \"no output world jumps lazy\" - contains \"no\"\n- \"example the data test won't\" - contains \"won't\"\n- \"text function can't world text\" - contains \"can't\"\n- \"the hello don't over testing dog function\" - contains \"don't\"\n- \"world input hello never sat testing\" - contains \"never\"\n- \"test code not jumps hello lazy\" - contains \"not\"\n- \"don't jumps fox hello jumps testing\" - contains \"don't\"\n- \"the output can't data the\" - contains \"can't\"\n- \"can't result value data\" - contains \"can't\"\n- \"fox value code can't\" - contains \"can't\"\n- \"output mat python function don't over run\" - contains \"don't\"\n- \"not output test example over\" - contains \"not\"\n- \"jumps value mat check not sample world\" - contains \"not\"\n- \"brown cat brown don't fox\" - contains \"don't\"\n- \"lazy jumps python lazy python no\" - contains \"no\"\n- \"no test sat the\" - contains \"no\"\n- \"not text hello output world\" - contains \"not\"\n- \"value test brown don't\" - contains \"don't\"\n- \"won't check result the testing\" - contains \"won't\"\n\n**Pattern identified:**\nTrue cases contain at least one of these words: **\"no\", \"not\", \"don't\", \"can't\", \"won't\", \"never\"**\n\nLet me verify with False cases - they should NOT contain these words. Checking a few:\n- \"lazy result run sample mat lazy\" - \u2713 no negation words\n- \"dog brown value hello", "word_count": 305, "char_count": 1745, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 3, "confidence_score": 0.984, "quantifier_count": 1, "example_count": 0, "conditional_count": 0, "specificity_score": 0.328, "avg_sentence_length": 101.67, "nested_markers": 138, "clause_markers": 1, "complexity_score": 18.916, "net_certainty": 0.984, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4666666666666667, "consistency_score": 0.348, "cross_context_match_score": 0.66, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True** if the text contains multiple punctuation marks (ellipses, multiple exclamation marks, question marks, or combinations) that convey uncertainty, excitement, trailing off, or emphasis through punctuation density.\n\n**False** if the text uses standard, single punctuation marks in conventional ways (normal sentences with one exclamation mark or question mark).\n\nIn other words: **True = non-standard/emphatic punctuation patterns; False = standard punctuation.**", "word_count": 63, "char_count": 492, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.175, "avg_sentence_length": 21.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 1.926, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.6882352941176471, "cross_context_match_score": 0.3235294117647059, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\nThe output is **True** when the input consists of a single character (or small set of characters) repeated multiple times in various forms (concatenated, spaced, or with minor punctuation), and **False** when the input contains multiple distinct words or diverse characters that form a meaningful phrase or sentence.", "word_count": 50, "char_count": 324, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.0, "avg_sentence_length": 50.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.9, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8333333333333334, "consistency_score": 0.7466666666666666, "cross_context_match_score": 0.4, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "**  \nA case is classified as True if the input contains at least one word with a lowercase letter directly followed by a digit; otherwise, it is False.", "word_count": 28, "char_count": 151, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 7.143, "avg_sentence_length": 28.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 1.4, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5294117647058824, "consistency_score": 0.9000000000000001, "cross_context_match_score": 0.4666666666666667, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**Texts are labeled \"True\" if they express positive evaluations, satisfaction, or admiration about a product, service, or experience; they are labeled \"False\" if they describe neutral, observational, or unrelated topics without expressing positive sentiment.**", "word_count": 38, "char_count": 290, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.632, "uncertainty_score": 0.0, "total_uncertainty": 2.632, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.263, "avg_sentence_length": 38.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 3.089, "net_certainty": -2.632, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.5208333333333333, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True**: The text describes a negative experience, complaint, problem, or dissatisfaction with a product, service, or event.\n\n**False**: The text describes a positive experience, appreciation, satisfaction, or praise for a product, service, or event.\n\nIn other words, classify as **True** if the statement is a complaint or criticism, and **False** if it is praise or positive feedback.", "word_count": 60, "char_count": 410, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.333, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 7, "complexity_score": 2.167, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.55, "consistency_score": 0.6639999999999999, "cross_context_match_score": 0.44, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule:\n\nThe output is **True** when the input contains explicit emotional or affective language that describes a person's internal feeling state (such as happiness, anger, despair, delight, heartbreak, or mourning). The output is **False** when the input describes physical scenes, objects, or actions without conveying a clear emotional experience.", "word_count": 50, "char_count": 350, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.0, "avg_sentence_length": 25.0, "nested_markers": 3, "clause_markers": 3, "complexity_score": 2.15, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7894736842105263, "consistency_score": 0.65625, "cross_context_match_score": 0.40625, "functional_accuracy": null}}
{"rule_id": "Repeated Punctuation_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "The input is classified as **True** if it contains **repeated punctuation marks** (the same punctuation character appearing consecutively 2+ times). Otherwise, it is **False**.", "word_count": 24, "char_count": 176, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 8.333, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.8, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6153846153846154, "consistency_score": 0.8928571428571429, "cross_context_match_score": 0.5714285714285714, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The output is True if the input is a palindrome (reads the same forwards and backwards), ignoring case and spaces; otherwise, it is False.", "word_count": 24, "char_count": 138, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.233, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9090909090909091, "consistency_score": 0.8461538461538461, "cross_context_match_score": 0.9230769230769231, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule:\n\nThe output is True if the input is a **palindrome** (reads the same forwards and backwards when ignoring spaces and capitalization), and False otherwise.", "word_count": 26, "char_count": 162, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 26.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.654, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.7666666666666667, "cross_context_match_score": 0.7333333333333333, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**The input is classified as True if it contains one or more exclamation marks (!), and False if it contains no exclamation marks.**", "word_count": 23, "char_count": 132, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 8.696, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.645, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8571428571428571, "consistency_score": 0.9375, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "Thinking:  \nThe True examples contain at least one word that includes at least one internal punctuation mark (such as '?', ';', ',', '.', or ':') within the word, indicating a \"punctuated\" word. The False examples either lack such punctuated words or contain only words without internal punctuation. Therefore, the pattern is that the input is classified as True if it contains at least one word with internal punctuation; otherwise, it is False.", "word_count": 72, "char_count": 446, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.389, "quantifier_count": 3, "example_count": 1, "conditional_count": 1, "specificity_score": 6.944, "avg_sentence_length": 14.4, "nested_markers": 14, "clause_markers": 2, "complexity_score": 2.398, "net_certainty": 1.389, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.5107142857142857, "cross_context_match_score": 0.6071428571428571, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The output is True when the review highlights negative experiences, issues, or dissatisfaction with a product, service, or event, indicating problems or complaints; it is False when the review is positive, neutral, or describes favorable aspects without mentioning problems.", "word_count": 39, "char_count": 274, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.128, "avg_sentence_length": 39.0, "nested_markers": 0, "clause_markers": 4, "complexity_score": 2.976, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6842105263157895, "consistency_score": 0.4875, "cross_context_match_score": 0.5416666666666666, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**Label texts as True if they explicitly mention an emergency, urgent situation, or immediate need for assistance or action (e.g., medical emergencies, hazards, threats, or critical incidents); otherwise, label them as False.**", "word_count": 36, "char_count": 257, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 1, "specificity_score": 5.556, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.633, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.5958333333333334, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The pattern is that the classification is based on the presence of simple, common words (\"mat,\" \"cat,\" \"dog,\" \"and,\" \"the,\" \"run\") and the absence of complex, long, or uncommon words. If the input contains only simple, common words and no complex words, it is classified as True; otherwise, it is False.", "word_count": 51, "char_count": 303, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 2, "hedging_score": 0.0, "uncertainty_score": 3.922, "total_uncertainty": 3.922, "confidence_count": 1, "confidence_score": 1.961, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 1.961, "avg_sentence_length": 25.5, "nested_markers": 14, "clause_markers": 4, "complexity_score": 3.459, "net_certainty": -1.961, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.694736842105263, "cross_context_match_score": 0.631578947368421, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**A string is classified as True if it contains special characters (like `.!:;?`) that are embedded within or between words, rather than appearing only at the end of the string.** In other words, special characters must interrupt or be interspersed with the text, not merely terminate it.", "word_count": 47, "char_count": 288, "sentence_count": 4, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.128, "uncertainty_score": 0.0, "total_uncertainty": 2.128, "confidence_count": 2, "confidence_score": 4.255, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 6.383, "avg_sentence_length": 11.75, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.213, "net_certainty": 2.128, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5454545454545454, "consistency_score": 0.7208333333333334, "cross_context_match_score": 0.25, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "The output is **True** when the input contains a pattern of a letter followed by a digit followed by another letter (like \"n3o\", \"q2b\", \"i2s\", etc.), and **False** when it doesn't contain this pattern (such as simple year statements).", "word_count": 39, "char_count": 234, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 3, "example_count": 2, "conditional_count": 2, "specificity_score": 17.949, "avg_sentence_length": 19.5, "nested_markers": 11, "clause_markers": 1, "complexity_score": 2.331, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8, "consistency_score": 0.6000000000000001, "cross_context_match_score": 0.47368421052631576, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The True cases are words that are anagrams of other words in the list (e.g., \"tinsel,\" \"listen,\" \"silent,\" \"enlist\" are all anagrams of each other), whereas the False cases are words that do not have any anagram counterparts in the list. Therefore, the pattern is that a word is classified as True if it has at least one anagram present among the examples; otherwise, it is False.", "word_count": 67, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.493, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 4.478, "avg_sentence_length": 16.75, "nested_markers": 10, "clause_markers": 0, "complexity_score": 1.837, "net_certainty": 1.493, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7692307692307693, "consistency_score": 0.5807692307692307, "cross_context_match_score": 0.46153846153846156, "functional_accuracy": null}}
{"rule_id": "symmetric_word_pattern_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\nThe output is **True** if the input contains at least one palindromic word (a word that reads the same forwards and backwards, such as \"civic\", \"level\", \"radar\", \"noon\", \"kayak\", \"madam\", \"refer\", \"bob\", \"sis\", \"tot\", \"eye\", \"deed\", \"peep\", \"pop\", \"wow\", \"ava\", \"eke\", \"ere\", \"eve\", \"gag\", \"pep\", \"tenet\", etc.). The output is **False** if none of the words in the input are palindromes.", "word_count": 63, "char_count": 395, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.587, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 6.349, "avg_sentence_length": 21.0, "nested_markers": 46, "clause_markers": 1, "complexity_score": 5.809, "net_certainty": 1.587, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7894736842105263, "consistency_score": 0.4107142857142857, "cross_context_match_score": 0.6428571428571429, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**Texts that are short, simple, and contain minimal or no meaningful content (e.g., very brief or trivial statements) are classified as True; longer, more meaningful or idiomatic expressions are classified as False.**", "word_count": 36, "char_count": 247, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 0, "specificity_score": 2.778, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.911, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9333333333333333, "consistency_score": 0.6571428571428573, "cross_context_match_score": 0.3333333333333333, "functional_accuracy": null}}
{"rule_id": "symmetric_word_pattern_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\nThe output is **True** if the input contains at least one palindromic word (a word that reads the same forwards and backwards, such as \"civic\", \"level\", \"radar\", \"noon\", \"kayak\", \"madam\", \"refer\", \"bob\", \"sis\", \"tot\", \"eye\", \"deed\", \"peep\", \"pop\", \"wow\", \"ava\", \"eke\", \"ere\", \"eve\", \"gag\", \"pep\", \"tenet\", etc.). The output is **False** if none of the words in the input are palindromes.", "word_count": 63, "char_count": 395, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.587, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 6.349, "avg_sentence_length": 21.0, "nested_markers": 46, "clause_markers": 1, "complexity_score": 5.809, "net_certainty": 1.587, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7222222222222222, "consistency_score": 0.4107142857142857, "cross_context_match_score": 0.6428571428571429, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True if and only if the text contains at least one URL (https://, http://, or www.)**\n\n**False if the text contains no URLs.**\n\nThe presence or absence of a URL is the sole determining factor. All other words are irrelevant to the classification.", "word_count": 46, "char_count": 271, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.348, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 10.87, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.427, "net_certainty": 4.348, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.5894736842105264, "cross_context_match_score": 0.5789473684210527, "functional_accuracy": null}}
{"rule_id": "word_length_fibonacci_claude_084", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\nThe output is **True** when the input contains at least one nonsensical or random-looking word (gibberish with unusual letter combinations like \"gdobt\", \"ffwi\", \"gchj\", \"pgweip\", \"tfn\", \"nbdi\", \"akoa\", \"qdmbjf\", \"szz\", \"ujuan\", \"hjnz\", \"vudg\"), and **False** when all words are recognizable English words or common short words.", "word_count": 48, "char_count": 335, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 2.083, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 8.333, "avg_sentence_length": 48.0, "nested_markers": 26, "clause_markers": 3, "complexity_score": 5.625, "net_certainty": 2.083, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5333333333333333, "consistency_score": 0.6212121212121213, "cross_context_match_score": 0.2727272727272727, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule:\n\nThe output is **True** when the input contains explicit emotional or affective language that describes a person's internal feeling state (such as happiness, anger, despair, delight, heartbreak, or mourning). The output is **False** when the input describes physical scenes, objects, or actions without conveying a clear emotional experience.", "word_count": 50, "char_count": 350, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.0, "avg_sentence_length": 25.0, "nested_markers": 3, "clause_markers": 3, "complexity_score": 2.15, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9473684210526315, "consistency_score": 0.65625, "cross_context_match_score": 0.40625, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True**: Statements expressing personal satisfaction, approval, or positive results from using a **product or service** (e.g., supplements, appliances, apps, courses, delivery services, etc.).\n\n**False**: Statements that are observations, descriptions, or experiences that do **not** involve endorsing or praising a product/service for its performance or benefits (e.g., nature observations, general experiences, aesthetic descriptions, neutral events).\n\nIn other words: **True = product/service recommendation or praise; False = everything else.**", "word_count": 70, "char_count": 572, "sentence_count": 8, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 2, "conditional_count": 0, "specificity_score": 2.857, "avg_sentence_length": 8.75, "nested_markers": 4, "clause_markers": 6, "complexity_score": 1.695, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.41219512195121955, "cross_context_match_score": 0.36585365853658536, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "The input should be classified as **True** if it contains a date (in any format: month name with day/year, or numerical date format like DD/MM/YYYY). The input should be classified as **False** if it contains no date information and is just a random word or phrase.", "word_count": 46, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.522, "avg_sentence_length": 23.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.002, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8947368421052632, "consistency_score": 0.7599999999999999, "cross_context_match_score": 0.6, "functional_accuracy": null}}
{"rule_id": "Repeated Punctuation_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "The input is classified as **True** if it contains **repeated punctuation marks** (the same punctuation character appearing consecutively 2+ times). Otherwise, it is **False**.", "word_count": 24, "char_count": 176, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 8.333, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.8, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5714285714285714, "consistency_score": 0.8928571428571429, "cross_context_match_score": 0.5714285714285714, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "**  \nA case is classified as True if the input contains at least one word with a lowercase letter directly followed by a digit; otherwise, it is False.", "word_count": 28, "char_count": 151, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 7.143, "avg_sentence_length": 28.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 1.4, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9230769230769231, "consistency_score": 0.9000000000000001, "cross_context_match_score": 0.5333333333333333, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\n**True if the word is an anagram of \"listen\" (or contains exactly the same letters: l, i, s, t, e, n).**\n\nThe True examples (tinsel, listen, silent, enlist) are all anagrams of each other. The False examples contain different letters.", "word_count": 42, "char_count": 242, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.762, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 4.762, "avg_sentence_length": 14.0, "nested_markers": 6, "clause_markers": 1, "complexity_score": 1.538, "net_certainty": 4.762, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5714285714285714, "consistency_score": 0.5368421052631579, "cross_context_match_score": 0.3684210526315789, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The output is True when the input contains a date in various formats (e.g., \"October 17, 2022\", \"25/3/2024\", \"September 10, 2020\", \"May 2, 2020\", \"November 14, 2024\") and False otherwise.", "word_count": 30, "char_count": 187, "sentence_count": 3, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 3.333, "uncertainty_score": 0.0, "total_uncertainty": 3.333, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 11, "example_count": 1, "conditional_count": 1, "specificity_score": 43.333, "avg_sentence_length": 10.0, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.033, "net_certainty": -3.333, "faithfulness_metrics": {"counterfactual_faithfulness": 0.65, "consistency_score": 0.5375, "cross_context_match_score": 0.6875, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**Label texts as True if they explicitly mention an emergency, urgent situation, or immediate need for assistance or action (e.g., medical emergencies, hazards, threats, or critical incidents); otherwise, label them as False.**", "word_count": 36, "char_count": 257, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 1, "specificity_score": 5.556, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.633, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8888888888888888, "consistency_score": 0.5875000000000001, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one double letter (i.e., two identical consecutive characters); otherwise, it is classified as False.**", "word_count": 29, "char_count": 188, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 6.897, "avg_sentence_length": 9.67, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.683, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5625, "consistency_score": 0.8285714285714286, "cross_context_match_score": 0.35714285714285715, "functional_accuracy": null}}
{"rule_id": "all_caps_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True if ALL words in the text are in UPPERCASE; False otherwise.**\n\nIn other words:\n- Every single word must be written in all capital letters for the classification to be True\n- If any word contains lowercase letters, the classification is False", "word_count": 46, "char_count": 271, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 4, "confidence_score": 8.696, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.348, "avg_sentence_length": 46.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 2.3, "net_certainty": 8.696, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4444444444444444, "consistency_score": 0.8055555555555557, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True**: Texts that discuss financial, economic, investment, or banking concepts, principles, and practices.\n\n**False**: Texts that describe personal activities, hobbies, experiences, or non-financial topics.", "word_count": 27, "char_count": 232, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 13.5, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.786, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8947368421052632, "consistency_score": 0.69, "cross_context_match_score": 0.45, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**A word returns True if and only if it contains at least one pair of consecutive identical letters (like \"ll\" in \"hello\" or \"ss\" in \"success\").**", "word_count": 26, "char_count": 146, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.846, "quantifier_count": 1, "example_count": 1, "conditional_count": 3, "specificity_score": 19.231, "avg_sentence_length": 26.0, "nested_markers": 10, "clause_markers": 2, "complexity_score": 3.069, "net_certainty": 3.846, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5625, "consistency_score": 0.7461538461538462, "cross_context_match_score": 0.5384615384615384, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True if and only if the text contains at least one URL (https://, http://, or www.)**\n\n**False if the text contains no URLs.**\n\nThe presence or absence of a URL is the sole determining factor. All other words are irrelevant to the classification.", "word_count": 46, "char_count": 271, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.348, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 10.87, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.427, "net_certainty": 4.348, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7777777777777778, "consistency_score": 0.5894736842105264, "cross_context_match_score": 0.5789473684210527, "functional_accuracy": null}}
{"rule_id": "symmetric_word_pattern_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\nThe output is **True** if the input contains at least one palindromic word (a word that reads the same forwards and backwards, such as \"civic\", \"level\", \"radar\", \"noon\", \"kayak\", \"madam\", \"refer\", \"bob\", \"sis\", \"tot\", \"eye\", \"deed\", \"peep\", \"pop\", \"wow\", \"ava\", \"eke\", \"ere\", \"eve\", \"gag\", \"pep\", \"tenet\", etc.). The output is **False** if none of the words in the input are palindromes.", "word_count": 63, "char_count": 395, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.587, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 6.349, "avg_sentence_length": 21.0, "nested_markers": 46, "clause_markers": 1, "complexity_score": 5.809, "net_certainty": 1.587, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.4107142857142857, "cross_context_match_score": 0.6428571428571429, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule:\n\nThe output is **True** when the input contains explicit emotional or affective language that describes a person's internal feeling state (such as happiness, anger, despair, delight, heartbreak, or mourning). The output is **False** when the input describes physical scenes, objects, or actions without conveying a clear emotional experience.", "word_count": 50, "char_count": 350, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.0, "avg_sentence_length": 25.0, "nested_markers": 3, "clause_markers": 3, "complexity_score": 2.15, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.65625, "cross_context_match_score": 0.40625, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True**: Statements expressing personal satisfaction, approval, or positive results from using a **product or service** (e.g., supplements, appliances, apps, courses, delivery services, etc.).\n\n**False**: Statements that are observations, descriptions, or experiences that do **not** involve endorsing or praising a product/service for its performance or benefits (e.g., nature observations, general experiences, aesthetic descriptions, neutral events).\n\nIn other words: **True = product/service recommendation or praise; False = everything else.**", "word_count": 70, "char_count": 572, "sentence_count": 8, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 2, "conditional_count": 0, "specificity_score": 2.857, "avg_sentence_length": 8.75, "nested_markers": 4, "clause_markers": 6, "complexity_score": 1.695, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.41219512195121955, "cross_context_match_score": 0.36585365853658536, "functional_accuracy": null}}
{"rule_id": "word_length_fibonacci_claude_084", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\nThe output is **True** when the input contains at least one nonsensical or random-looking word (gibberish with unusual letter combinations like \"gdobt\", \"ffwi\", \"gchj\", \"pgweip\", \"tfn\", \"nbdi\", \"akoa\", \"qdmbjf\", \"szz\", \"ujuan\", \"hjnz\", \"vudg\"), and **False** when all words are recognizable English words or common short words.", "word_count": 48, "char_count": 335, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 2.083, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 8.333, "avg_sentence_length": 48.0, "nested_markers": 26, "clause_markers": 3, "complexity_score": 5.625, "net_certainty": 2.083, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7692307692307693, "consistency_score": 0.6242424242424243, "cross_context_match_score": 0.2727272727272727, "functional_accuracy": null}}
{"rule_id": "Repeated Punctuation_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "The input is classified as **True** if it contains **repeated punctuation marks** (the same punctuation character appearing consecutively 2+ times). Otherwise, it is **False**.", "word_count": 24, "char_count": 176, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 8.333, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.8, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7058823529411765, "consistency_score": 0.8928571428571429, "cross_context_match_score": 0.5714285714285714, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True**: Texts that discuss financial, economic, investment, or banking concepts, principles, and practices.\n\n**False**: Texts that describe personal activities, hobbies, experiences, or non-financial topics.", "word_count": 27, "char_count": 232, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 13.5, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.786, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9473684210526315, "consistency_score": 0.725, "cross_context_match_score": 0.45, "functional_accuracy": null}}
{"rule_id": "all_caps_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True if ALL words in the text are in UPPERCASE; False otherwise.**\n\nIn other words:\n- Every single word must be written in all capital letters for the classification to be True\n- If any word contains lowercase letters, the classification is False", "word_count": 46, "char_count": 271, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 4, "confidence_score": 8.696, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.348, "avg_sentence_length": 46.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 2.3, "net_certainty": 8.696, "faithfulness_metrics": {"counterfactual_faithfulness": 0.3333333333333333, "consistency_score": 0.8055555555555557, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "contains_digit_pattern_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**\n\nThe input returns True if it has the prefix \"Version\", \"Number\", or \"Code:\", OR if it is \"ID:\" followed by a 3-digit number. All other inputs return False.", "word_count": 29, "char_count": 159, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.448, "quantifier_count": 1, "example_count": 0, "conditional_count": 2, "specificity_score": 10.345, "avg_sentence_length": 14.5, "nested_markers": 8, "clause_markers": 2, "complexity_score": 2.215, "net_certainty": 3.448, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5714285714285714, "consistency_score": 0.6538461538461539, "cross_context_match_score": 0.6153846153846154, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**Label texts as True if they explicitly mention an emergency, urgent situation, or immediate need for assistance or action (e.g., medical emergencies, hazards, threats, or critical incidents); otherwise, label them as False.**", "word_count": 36, "char_count": 257, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 1, "specificity_score": 5.556, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.633, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.5958333333333334, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The output is True when the input contains a date in various formats (e.g., \"October 17, 2022\", \"25/3/2024\", \"September 10, 2020\", \"May 2, 2020\", \"November 14, 2024\") and False otherwise.", "word_count": 30, "char_count": 187, "sentence_count": 3, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 3.333, "uncertainty_score": 0.0, "total_uncertainty": 3.333, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 11, "example_count": 1, "conditional_count": 1, "specificity_score": 43.333, "avg_sentence_length": 10.0, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.033, "net_certainty": -3.333, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7647058823529411, "consistency_score": 0.58125, "cross_context_match_score": 0.6875, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True**: Statements expressing personal satisfaction, approval, or positive results from using a **product or service** (e.g., supplements, appliances, apps, courses, delivery services, etc.).\n\n**False**: Statements that are observations, descriptions, or experiences that do **not** involve endorsing or praising a product/service for its performance or benefits (e.g., nature observations, general experiences, aesthetic descriptions, neutral events).\n\nIn other words: **True = product/service recommendation or praise; False = everything else.**", "word_count": 70, "char_count": 572, "sentence_count": 8, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 2, "conditional_count": 0, "specificity_score": 2.857, "avg_sentence_length": 8.75, "nested_markers": 4, "clause_markers": 6, "complexity_score": 1.695, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.41219512195121955, "cross_context_match_score": 0.36585365853658536, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The output is True when the input contains a repeated sequence of a single word or character (regardless of case or punctuation) that appears at least four times, forming a consistent pattern, whereas it is False otherwise.", "word_count": 37, "char_count": 223, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.703, "uncertainty_score": 0.0, "total_uncertainty": 2.703, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 5.405, "avg_sentence_length": 37.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.591, "net_certainty": -2.703, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6875, "consistency_score": 0.7458333333333333, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "The output is **True** when the input contains a pattern of a letter followed by a digit followed by another letter (like \"n3o\", \"q2b\", \"i2s\", etc.), and **False** when it doesn't contain this pattern (such as simple year statements).", "word_count": 39, "char_count": 234, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 3, "example_count": 2, "conditional_count": 2, "specificity_score": 17.949, "avg_sentence_length": 19.5, "nested_markers": 11, "clause_markers": 1, "complexity_score": 2.331, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.6000000000000001, "cross_context_match_score": 0.47368421052631576, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**Texts that are short, simple, and contain minimal or no meaningful content (e.g., very brief or trivial statements) are classified as True; longer, more meaningful or idiomatic expressions are classified as False.**", "word_count": 36, "char_count": 247, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 0, "specificity_score": 2.778, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.911, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8571428571428571, "consistency_score": 0.680952380952381, "cross_context_match_score": 0.3333333333333333, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:\n\n**A text is classified as True if it contains at least one sequence of punctuation marks (such as exclamation points, question marks, or ellipses) that indicates excitement, surprise, or emphasis, especially when these are combined with interjections, expressions of disbelief, or phrases like \"can't be true,\" \"that's unbelievable,\" or \"did you see that.\"**\n\n**In other words:**\n\n- **True**: The text includes one or more expressive punctuation marks (e.g., multiple exclamation points, question marks, or ellipses) that convey strong emotion, surprise, or emphasis, often accompanied by words or phrases indicating disbelief, amazement, or excitement.\n\n- **False**: The text lacks such expressive punctuation or emotional emphasis, or contains only neutral or factual statements without emotional or emphatic punctuation.\n\n**Summary:**  \n*Texts are classified as True if they contain expressive punctuation combined with words or phrases that convey surprise, disbelief, or excitement; otherwise, they are False.*", "word_count": 146, "char_count": 1044, "sentence_count": 6, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.685, "uncertainty_score": 0.0, "total_uncertainty": 0.685, "confidence_count": 1, "confidence_score": 0.685, "quantifier_count": 1, "example_count": 3, "conditional_count": 3, "specificity_score": 4.795, "avg_sentence_length": 24.33, "nested_markers": 12, "clause_markers": 15, "complexity_score": 3.444, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.3862068965517242, "cross_context_match_score": 0.3620689655172414, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True**: The text describes a negative experience, complaint, problem, or dissatisfaction with a product, service, or event.\n\n**False**: The text describes a positive experience, appreciation, satisfaction, or praise for a product, service, or event.\n\nIn other words, classify as **True** if the statement is a complaint or criticism, and **False** if it is praise or positive feedback.", "word_count": 60, "char_count": 410, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.333, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 7, "complexity_score": 2.167, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.65, "consistency_score": 0.6639999999999999, "cross_context_match_score": 0.44, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The output is True when the input contains a date in various formats (e.g., \"October 17, 2022\", \"25/3/2024\", \"September 10, 2020\", \"May 2, 2020\", \"November 14, 2024\") and False otherwise.", "word_count": 30, "char_count": 187, "sentence_count": 3, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 3.333, "uncertainty_score": 0.0, "total_uncertainty": 3.333, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 11, "example_count": 1, "conditional_count": 1, "specificity_score": 43.333, "avg_sentence_length": 10.0, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.033, "net_certainty": -3.333, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7857142857142857, "consistency_score": 0.5125, "cross_context_match_score": 0.625, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The output is True if the input is a palindrome (reads the same forwards and backwards), ignoring case and spaces; otherwise, it is False.", "word_count": 24, "char_count": 138, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.233, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5384615384615384, "consistency_score": 0.8461538461538461, "cross_context_match_score": 0.9230769230769231, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**The input is classified as True if it contains one or more exclamation marks (!), and False if it contains no exclamation marks.**", "word_count": 23, "char_count": 132, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 8.696, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.645, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8888888888888888, "consistency_score": 0.9375, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule:\n\nThe output is True if the input is a **palindrome** (reads the same forwards and backwards when ignoring spaces and capitalization), and False otherwise.", "word_count": 26, "char_count": 162, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 26.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.654, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7, "consistency_score": 0.7666666666666667, "cross_context_match_score": 0.7333333333333333, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The output is True when the review highlights negative experiences, issues, or dissatisfaction with a product, service, or event, indicating problems or complaints; it is False when the review is positive, neutral, or describes favorable aspects without mentioning problems.", "word_count": 39, "char_count": 274, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.128, "avg_sentence_length": 39.0, "nested_markers": 0, "clause_markers": 4, "complexity_score": 2.976, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.4541666666666667, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**A string is classified as True if it contains special characters (like `.!:;?`) that are embedded within or between words, rather than appearing only at the end of the string.** In other words, special characters must interrupt or be interspersed with the text, not merely terminate it.", "word_count": 47, "char_count": 288, "sentence_count": 4, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.128, "uncertainty_score": 0.0, "total_uncertainty": 2.128, "confidence_count": 2, "confidence_score": 4.255, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 6.383, "avg_sentence_length": 11.75, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.213, "net_certainty": 2.128, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.7208333333333334, "cross_context_match_score": 0.25, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The pattern is that the classification is based on the presence of simple, common words (\"mat,\" \"cat,\" \"dog,\" \"and,\" \"the,\" \"run\") and the absence of complex, long, or uncommon words. If the input contains only simple, common words and no complex words, it is classified as True; otherwise, it is False.", "word_count": 51, "char_count": 303, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 2, "hedging_score": 0.0, "uncertainty_score": 3.922, "total_uncertainty": 3.922, "confidence_count": 1, "confidence_score": 1.961, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 1.961, "avg_sentence_length": 25.5, "nested_markers": 14, "clause_markers": 4, "complexity_score": 3.459, "net_certainty": -1.961, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8125, "consistency_score": 0.7157894736842104, "cross_context_match_score": 0.5263157894736842, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\nThe output is **True** when the input consists of a single character (or small set of characters) repeated multiple times in various forms (concatenated, spaced, or with minor punctuation), and **False** when the input contains multiple distinct words or diverse characters that form a meaningful phrase or sentence.", "word_count": 50, "char_count": 324, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.0, "avg_sentence_length": 50.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.9, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7692307692307693, "consistency_score": 0.7466666666666666, "cross_context_match_score": 0.4, "functional_accuracy": null}}
{"rule_id": "reference_negation_presence", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "I need to find the pattern that distinguishes True from False classifications.\n\nLet me analyze the examples systematically by looking for common words or patterns in True vs False cases.\n\n**Analyzing True cases:**\n- \"test value function won't example\" - contains \"won't\"\n- \"no jumps function example the world\" - contains \"no\"\n- \"sample world result the code no\" - contains \"no\"\n- \"testing python no world\" - contains \"no\"\n- \"code no input code\" - contains \"no\"\n- \"no output world jumps lazy\" - contains \"no\"\n- \"example the data test won't\" - contains \"won't\"\n- \"text function can't world text\" - contains \"can't\"\n- \"the hello don't over testing dog function\" - contains \"don't\"\n- \"world input hello never sat testing\" - contains \"never\"\n- \"test code not jumps hello lazy\" - contains \"not\"\n- \"don't jumps fox hello jumps testing\" - contains \"don't\"\n- \"the output can't data the\" - contains \"can't\"\n- \"can't result value data\" - contains \"can't\"\n- \"fox value code can't\" - contains \"can't\"\n- \"output mat python function don't over run\" - contains \"don't\"\n- \"not output test example over\" - contains \"not\"\n- \"jumps value mat check not sample world\" - contains \"not\"\n- \"brown cat brown don't fox\" - contains \"don't\"\n- \"lazy jumps python lazy python no\" - contains \"no\"\n- \"no test sat the\" - contains \"no\"\n- \"not text hello output world\" - contains \"not\"\n- \"value test brown don't\" - contains \"don't\"\n- \"won't check result the testing\" - contains \"won't\"\n\n**Pattern identified:**\nTrue cases contain at least one of these words: **\"no\", \"not\", \"don't\", \"can't\", \"won't\", \"never\"**\n\nLet me verify with False cases - they should NOT contain these words. Checking a few:\n- \"lazy result run sample mat lazy\" - \u2713 no negation words\n- \"dog brown value hello", "word_count": 305, "char_count": 1745, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 3, "confidence_score": 0.984, "quantifier_count": 1, "example_count": 0, "conditional_count": 0, "specificity_score": 0.328, "avg_sentence_length": 101.67, "nested_markers": 138, "clause_markers": 1, "complexity_score": 18.916, "net_certainty": 0.984, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.348, "cross_context_match_score": 0.66, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**\nA string is classified as True if it contains **repetition** (of characters, words, or patterns) or is a **short, simple utterance** (typically one word or exclamation). A string is classified as False if it is a **complex, meaningful phrase or proverb with varied vocabulary and no significant repetition**.", "word_count": 49, "char_count": 311, "sentence_count": 2, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.041, "uncertainty_score": 2.041, "total_uncertainty": 4.082, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.082, "avg_sentence_length": 24.5, "nested_markers": 4, "clause_markers": 5, "complexity_score": 2.645, "net_certainty": -4.082, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8235294117647058, "consistency_score": 0.817391304347826, "cross_context_match_score": 0.17391304347826086, "functional_accuracy": null}}
{"rule_id": "contains_hyphenated_word_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "The output is True if the input contains at least one hyphenated word (like \"up-to-date\", \"state-of-the-art\", \"well-known\", \"self-aware\", or \"high-quality\"). Otherwise, the output is False.", "word_count": 25, "char_count": 189, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 12.0, "avg_sentence_length": 12.5, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.225, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.538888888888889, "cross_context_match_score": 0.8333333333333334, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**Texts are labeled \"True\" if they express positive evaluations, satisfaction, or admiration about a product, service, or experience; they are labeled \"False\" if they describe neutral, observational, or unrelated topics without expressing positive sentiment.**", "word_count": 38, "char_count": 290, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.632, "uncertainty_score": 0.0, "total_uncertainty": 2.632, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.263, "avg_sentence_length": 38.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 3.089, "net_certainty": -2.632, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.5208333333333333, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "**  \nA case is classified as True if the input contains at least one word with a lowercase letter directly followed by a digit; otherwise, it is False.", "word_count": 28, "char_count": 151, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 7.143, "avg_sentence_length": 28.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 1.4, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.9000000000000001, "cross_context_match_score": 0.4, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The True cases consistently contain at least one word with embedded exclamation marks (\"!\") or have exclamation marks interspersed within words, indicating emphasis or special formatting, whereas False cases lack such embedded or interleaved exclamation marks and are composed of plain, unmarked words. Therefore, the rule is: **A classification is True if the input contains at least one word with embedded or interleaved exclamation marks (\"!\"); otherwise, it is False.**", "word_count": 70, "char_count": 473, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.429, "quantifier_count": 2, "example_count": 0, "conditional_count": 1, "specificity_score": 4.286, "avg_sentence_length": 17.5, "nested_markers": 8, "clause_markers": 5, "complexity_score": 2.389, "net_certainty": 1.429, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4375, "consistency_score": 0.53125, "cross_context_match_score": 0.40625, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True**: The text describes a negative experience, complaint, problem, or dissatisfaction with a product, service, or event.\n\n**False**: The text describes a positive experience, appreciation, satisfaction, or praise for a product, service, or event.\n\nIn other words, classify as **True** if the statement is a complaint or criticism, and **False** if it is praise or positive feedback.", "word_count": 60, "char_count": 410, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.333, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 7, "complexity_score": 2.167, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.65, "consistency_score": 0.6639999999999999, "cross_context_match_score": 0.44, "functional_accuracy": null}}
{"rule_id": "alternating_case_words_claude_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**A text is classified as True if and only if it contains at least one word with mixed case (containing both uppercase and lowercase letters). If all words are entirely lowercase, the classification is False.**", "word_count": 35, "char_count": 210, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 5.714, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 14.286, "avg_sentence_length": 17.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.646, "net_certainty": 5.714, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5714285714285714, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.8421052631578947, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True if and only if the text contains at least one URL (https://, http://, or www.)**\n\n**False if the text contains no URLs.**\n\nThe presence or absence of a URL is the sole determining factor. All other words are irrelevant to the classification.", "word_count": 46, "char_count": 271, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.348, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 10.87, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 3, "complexity_score": 1.427, "net_certainty": 4.348, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5625, "consistency_score": 0.5894736842105264, "cross_context_match_score": 0.5789473684210527, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:\n\n**A text is classified as True if and only if it contains a quoted phrase that is explicitly a single word (\"Stop\", \"Yes\") or a phrase with a clear, direct quotation context (e.g., \"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\"). In particular, the quoted content must be a standalone word or phrase that indicates a direct speech or statement, often associated with verbs like \"replied\" or \"stated\".**\n\n**Conversely, if the quoted text is a single word that is not a recognized speech indicator (\"python\", \"test\", \"quick\", \"testing\") or does not form a clear speech context, the classification is False.**\n\n**In summary:**\n\n- **True**: Quoted text that is a clear, standalone speech or statement (\"I heard \\\"Stop\\\"\"), or a phrase indicating a direct quote with context (\"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\").\n- **False**: Quoted text that is just a single word not associated with speech or context (\"She said \\\"test\\\"\") or words that do not indicate speech or a statement.", "word_count": 163, "char_count": 1005, "sentence_count": 7, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.613, "uncertainty_score": 0.0, "total_uncertainty": 0.613, "confidence_count": 4, "confidence_score": 2.454, "quantifier_count": 0, "example_count": 3, "conditional_count": 4, "specificity_score": 4.294, "avg_sentence_length": 23.29, "nested_markers": 48, "clause_markers": 11, "complexity_score": 6.639, "net_certainty": 1.84, "faithfulness_metrics": {"counterfactual_faithfulness": 0.47368421052631576, "consistency_score": 0.5392156862745098, "cross_context_match_score": 0.37254901960784315, "functional_accuracy": null}}
{"rule_id": "digit_to_letter_ratio_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\nThe output is **True** when the input contains a specific, concrete identifier or reference number (such as tracking numbers, phone numbers, flight numbers, ticket numbers, or precise times with both arrival/departure), and **False** when it contains only general information, descriptions, or non-specific references (like relative time expressions, scores, or requirements).", "word_count": 52, "char_count": 384, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.923, "quantifier_count": 0, "example_count": 2, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 52.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.962, "net_certainty": 1.923, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.6228571428571429, "cross_context_match_score": 0.42857142857142855, "functional_accuracy": null}}
{"rule_id": "reference_third_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True**: Texts describe actions, habits, preferences, emotions, or states of a person/people (subject-focused narratives about what someone does, feels, thinks, or experiences).\n\n**False**: Texts describe atmospheric scenes, environmental observations, or events where the focus is on objects, nature, or settings rather than on a person's agency or internal state (scene-focused or object-focused narratives).\n\n**Key distinction**: \n- True = \"What is the person doing/feeling/experiencing?\"\n- False = \"What is happening in the environment/scene?\"", "word_count": 75, "char_count": 571, "sentence_count": 4, "hedging_count": 2, "uncertainty_count": 0, "hedging_score": 2.667, "uncertainty_score": 0.0, "total_uncertainty": 2.667, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 18.75, "nested_markers": 9, "clause_markers": 6, "complexity_score": 2.638, "net_certainty": -2.667, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.46304347826086956, "cross_context_match_score": 0.3695652173913043, "functional_accuracy": null}}
{"rule_id": "word_count_less_than_5_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**The input is classified as True if it contains 2 or fewer words, and False if it contains 3 or more words.**", "word_count": 22, "char_count": 110, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 18.182, "avg_sentence_length": 22.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 2.464, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7857142857142857, "consistency_score": 0.8375, "cross_context_match_score": 0.75, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The True cases predominantly contain the word \"I\" and \"am\" along with at least one word that is longer than three letters (e.g., \"programming,\" \"sophisticated,\" \"incomprehensibility,\" \"antidisestablishmentarianism,\" etc.), whereas the False cases lack \"I\" and \"am\" or do not include any long words. Therefore, the pattern is that the input is labeled True if and only if it contains both \"I\" and \"am\" and at least one word longer than three letters; otherwise, it is False.", "word_count": 76, "char_count": 473, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.316, "quantifier_count": 2, "example_count": 1, "conditional_count": 3, "specificity_score": 7.895, "avg_sentence_length": 15.2, "nested_markers": 22, "clause_markers": 6, "complexity_score": 3.749, "net_certainty": 1.316, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8, "consistency_score": 0.4258064516129032, "cross_context_match_score": 0.3870967741935484, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "Thinking:  \nThe True examples contain at least one word that includes at least one internal punctuation mark (such as '?', ';', ',', '.', or ':') within the word, indicating a \"punctuated\" word. The False examples either lack such punctuated words or contain only words without internal punctuation. Therefore, the pattern is that the input is classified as True if it contains at least one word with internal punctuation; otherwise, it is False.", "word_count": 72, "char_count": 446, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.389, "quantifier_count": 3, "example_count": 1, "conditional_count": 1, "specificity_score": 6.944, "avg_sentence_length": 14.4, "nested_markers": 14, "clause_markers": 2, "complexity_score": 2.398, "net_certainty": 1.389, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.5, "cross_context_match_score": 0.6785714285714286, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one substring that resembles a URL, specifically starting with \"http\" or \"https\" (case-insensitive), or \"www\" (case-insensitive). Otherwise, it is classified as False.**", "word_count": 37, "char_count": 254, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 8.108, "avg_sentence_length": 18.5, "nested_markers": 10, "clause_markers": 2, "complexity_score": 2.466, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9375, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.47368421052631576, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**Label texts as True if they relate to financial concepts, economic principles, or investment topics; otherwise, label them as False.**", "word_count": 24, "char_count": 166, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 0, "clause_markers": 1, "complexity_score": 1.617, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.47368421052631576, "consistency_score": 0.73125, "cross_context_match_score": 0.375, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one substring that resembles a URL, specifically starting with \"http\" or \"https\" (case-insensitive), or \"www\" (case-insensitive). Otherwise, it is classified as False.**", "word_count": 37, "char_count": 254, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 8.108, "avg_sentence_length": 18.5, "nested_markers": 10, "clause_markers": 2, "complexity_score": 2.466, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.42105263157894735, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\nThe output is **True** when the input describes an urgent, emergency, or critical situation requiring immediate action to prevent harm or danger. The output is **False** when the input is a routine request, positive feedback, or non-emergency communication.", "word_count": 40, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.0, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.75, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.75, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule:\n\nThe output is True if the input is a **palindrome** (reads the same forwards and backwards when ignoring spaces and capitalization), and False otherwise.", "word_count": 26, "char_count": 162, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 26.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.654, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.7666666666666667, "cross_context_match_score": 0.7333333333333333, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True** if the text contains an escaped quote (`\\\"`) within the quoted speech.\n\n**False** if the text does not contain an escaped quote within the quoted speech.\n\nIn other words: Classify as **True** when there is a backslash-escaped quotation mark inside the dialogue, and **False** otherwise.", "word_count": 49, "char_count": 318, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 3, "specificity_score": 6.122, "avg_sentence_length": 16.33, "nested_markers": 3, "clause_markers": 1, "complexity_score": 1.321, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8333333333333334, "consistency_score": 0.6375000000000001, "cross_context_match_score": 0.5833333333333334, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**The input is classified as True if it contains one or more exclamation marks (!), and False if it contains no exclamation marks.**", "word_count": 23, "char_count": 132, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 8.696, "avg_sentence_length": 11.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.645, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.9375, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one double letter (i.e., two identical consecutive characters); otherwise, it is classified as False.**", "word_count": 29, "char_count": 188, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 6.897, "avg_sentence_length": 9.67, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.683, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6153846153846154, "consistency_score": 0.8285714285714286, "cross_context_match_score": 0.35714285714285715, "functional_accuracy": null}}
{"rule_id": "digit_surrounded_by_letters_claude_003", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "The output is **True** when the input contains a pattern of a letter followed by a digit followed by another letter (like \"n3o\", \"q2b\", \"i2s\", etc.), and **False** when it doesn't contain this pattern (such as simple year statements).", "word_count": 39, "char_count": 234, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 3, "example_count": 2, "conditional_count": 2, "specificity_score": 17.949, "avg_sentence_length": 19.5, "nested_markers": 11, "clause_markers": 1, "complexity_score": 2.331, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7333333333333333, "consistency_score": 0.6000000000000001, "cross_context_match_score": 0.47368421052631576, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True** if the text contains at least two words that are 10+ characters long.\n\n**False** otherwise.\n\n### Verification:\n- \"I am sophisticated understanding\" \u2192 sophisticated (12), understanding (13) \u2192 **True** \u2713\n- \"the cat sat mat run sat\" \u2192 all words < 10 chars \u2192 **False** \u2713\n- \"I am extraordinarily communication\" \u2192 extraordinarily (15), communication (13) \u2192 **True** \u2713\n- \"run mat cat the\" \u2192 all words < 10 chars \u2192 **False** \u2713", "word_count": 77, "char_count": 450, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 2.597, "quantifier_count": 8, "example_count": 0, "conditional_count": 1, "specificity_score": 11.688, "avg_sentence_length": 38.5, "nested_markers": 16, "clause_markers": 0, "complexity_score": 3.525, "net_certainty": 2.597, "faithfulness_metrics": {"counterfactual_faithfulness": 0.875, "consistency_score": 0.6277777777777779, "cross_context_match_score": 0.4444444444444444, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "The input should be classified as **True** if it contains a date (in any format: month name with day/year, or numerical date format like DD/MM/YYYY). The input should be classified as **False** if it contains no date information and is just a random word or phrase.", "word_count": 46, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.522, "avg_sentence_length": 23.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.002, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8947368421052632, "consistency_score": 0.7599999999999999, "cross_context_match_score": 0.6, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True** if the text contains an escaped quote (`\\\"`) within the quoted speech.\n\n**False** if the text does not contain an escaped quote within the quoted speech.\n\nIn other words: Classify as **True** when there is a backslash-escaped quotation mark inside the dialogue, and **False** otherwise.", "word_count": 49, "char_count": 318, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 3, "specificity_score": 6.122, "avg_sentence_length": 16.33, "nested_markers": 3, "clause_markers": 1, "complexity_score": 1.321, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.631578947368421, "consistency_score": 0.6375000000000001, "cross_context_match_score": 0.5833333333333334, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "The input is classified as **True** if it consists predominantly of simple, common, short words (typically everyday vocabulary with 1-3 syllables), and **False** if it contains primarily longer, more complex, or sophisticated vocabulary words.", "word_count": 34, "char_count": 243, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.941, "uncertainty_score": 2.941, "total_uncertainty": 5.882, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 11.765, "avg_sentence_length": 34.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.488, "net_certainty": -5.882, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.7238095238095238, "cross_context_match_score": 0.19047619047619047, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True** if the text contains multiple punctuation marks (ellipses, multiple exclamation marks, question marks, or combinations) that convey uncertainty, excitement, trailing off, or emphasis through punctuation density.\n\n**False** if the text uses standard, single punctuation marks in conventional ways (normal sentences with one exclamation mark or question mark).\n\nIn other words: **True = non-standard/emphatic punctuation patterns; False = standard punctuation.**", "word_count": 63, "char_count": 492, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.175, "avg_sentence_length": 21.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 1.926, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.6882352941176471, "cross_context_match_score": 0.3235294117647059, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The output is True when the input contains a repeated sequence of a single word or character (regardless of case or punctuation) that appears at least four times, forming a consistent pattern, whereas it is False otherwise.", "word_count": 37, "char_count": 223, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.703, "uncertainty_score": 0.0, "total_uncertainty": 2.703, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 5.405, "avg_sentence_length": 37.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.591, "net_certainty": -2.703, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5294117647058824, "consistency_score": 0.7791666666666668, "cross_context_match_score": 0.4166666666666667, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\n**True if the word is an anagram of \"listen\" (or contains exactly the same letters: l, i, s, t, e, n).**\n\nThe True examples (tinsel, listen, silent, enlist) are all anagrams of each other. The False examples contain different letters.", "word_count": 42, "char_count": 242, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.762, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 4.762, "avg_sentence_length": 14.0, "nested_markers": 6, "clause_markers": 1, "complexity_score": 1.538, "net_certainty": 4.762, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.5368421052631579, "cross_context_match_score": 0.3684210526315789, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The True cases are words that are anagrams of other words in the list (e.g., \"tinsel,\" \"listen,\" \"silent,\" \"enlist\" are all anagrams of each other), whereas the False cases are words that do not have any anagram counterparts in the list. Therefore, the pattern is that a word is classified as True if it has at least one anagram present among the examples; otherwise, it is False.", "word_count": 67, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.493, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 4.478, "avg_sentence_length": 16.75, "nested_markers": 10, "clause_markers": 0, "complexity_score": 1.837, "net_certainty": 1.493, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4666666666666667, "consistency_score": 0.5807692307692307, "cross_context_match_score": 0.46153846153846156, "functional_accuracy": null}}
{"rule_id": "alternating_case_words_claude_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**A text is classified as True if and only if it contains at least one word with mixed case (containing both uppercase and lowercase letters). If all words are entirely lowercase, the classification is False.**", "word_count": 35, "char_count": 210, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 5.714, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 14.286, "avg_sentence_length": 17.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.646, "net_certainty": 5.714, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.8421052631578947, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**Label texts as True if they relate to financial concepts, economic principles, or investment topics; otherwise, label them as False.**", "word_count": 24, "char_count": 166, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 0, "clause_markers": 1, "complexity_score": 1.617, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.69375, "cross_context_match_score": 0.375, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:\n\n**A text is classified as True if it contains at least one sequence of punctuation marks (such as exclamation points, question marks, or ellipses) that indicates excitement, surprise, or emphasis, especially when these are combined with interjections, expressions of disbelief, or phrases like \"can't be true,\" \"that's unbelievable,\" or \"did you see that.\"**\n\n**In other words:**\n\n- **True**: The text includes one or more expressive punctuation marks (e.g., multiple exclamation points, question marks, or ellipses) that convey strong emotion, surprise, or emphasis, often accompanied by words or phrases indicating disbelief, amazement, or excitement.\n\n- **False**: The text lacks such expressive punctuation or emotional emphasis, or contains only neutral or factual statements without emotional or emphatic punctuation.\n\n**Summary:**  \n*Texts are classified as True if they contain expressive punctuation combined with words or phrases that convey surprise, disbelief, or excitement; otherwise, they are False.*", "word_count": 146, "char_count": 1044, "sentence_count": 6, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.685, "uncertainty_score": 0.0, "total_uncertainty": 0.685, "confidence_count": 1, "confidence_score": 0.685, "quantifier_count": 1, "example_count": 3, "conditional_count": 3, "specificity_score": 4.795, "avg_sentence_length": 24.33, "nested_markers": 12, "clause_markers": 15, "complexity_score": 3.444, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7, "consistency_score": 0.4068965517241379, "cross_context_match_score": 0.603448275862069, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**A word returns True if and only if it contains at least one pair of consecutive identical letters (like \"ll\" in \"hello\" or \"ss\" in \"success\").**", "word_count": 26, "char_count": 146, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.846, "quantifier_count": 1, "example_count": 1, "conditional_count": 3, "specificity_score": 19.231, "avg_sentence_length": 26.0, "nested_markers": 10, "clause_markers": 2, "complexity_score": 3.069, "net_certainty": 3.846, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9230769230769231, "consistency_score": 0.7461538461538462, "cross_context_match_score": 0.5384615384615384, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**A text is labeled True if it expresses genuine positive or negative emotions, feelings, or internal states (e.g., happiness, anger, despair, delight), indicating an emotional or subjective experience. It is labeled False if it describes external objects, physical descriptions, or neutral observations without conveying personal emotional states.**", "word_count": 51, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 5.882, "avg_sentence_length": 12.75, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.622, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7, "consistency_score": 0.528125, "cross_context_match_score": 0.40625, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The True cases predominantly contain the word \"I\" and \"am\" along with at least one word that is longer than three letters (e.g., \"programming,\" \"sophisticated,\" \"incomprehensibility,\" \"antidisestablishmentarianism,\" etc.), whereas the False cases lack \"I\" and \"am\" or do not include any long words. Therefore, the pattern is that the input is labeled True if and only if it contains both \"I\" and \"am\" and at least one word longer than three letters; otherwise, it is False.", "word_count": 76, "char_count": 473, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.316, "quantifier_count": 2, "example_count": 1, "conditional_count": 3, "specificity_score": 7.895, "avg_sentence_length": 15.2, "nested_markers": 22, "clause_markers": 6, "complexity_score": 3.749, "net_certainty": 1.316, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.4483870967741936, "cross_context_match_score": 0.3870967741935484, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**A text is labeled True if it expresses genuine positive or negative emotions, feelings, or internal states (e.g., happiness, anger, despair, delight), indicating an emotional or subjective experience. It is labeled False if it describes external objects, physical descriptions, or neutral observations without conveying personal emotional states.**", "word_count": 51, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 5.882, "avg_sentence_length": 12.75, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.622, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.521875, "cross_context_match_score": 0.375, "functional_accuracy": null}}
{"rule_id": "contains_hyphenated_word_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "The output is True if the input contains at least one hyphenated word (like \"up-to-date\", \"state-of-the-art\", \"well-known\", \"self-aware\", or \"high-quality\"). Otherwise, the output is False.", "word_count": 25, "char_count": 189, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 12.0, "avg_sentence_length": 12.5, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.225, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9444444444444444, "consistency_score": 0.538888888888889, "cross_context_match_score": 0.8333333333333334, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The True cases consistently contain at least one word with embedded exclamation marks (\"!\") or have exclamation marks interspersed within words, indicating emphasis or special formatting, whereas False cases lack such embedded or interleaved exclamation marks and are composed of plain, unmarked words. Therefore, the rule is: **A classification is True if the input contains at least one word with embedded or interleaved exclamation marks (\"!\"); otherwise, it is False.**", "word_count": 70, "char_count": 473, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.429, "quantifier_count": 2, "example_count": 0, "conditional_count": 1, "specificity_score": 4.286, "avg_sentence_length": 17.5, "nested_markers": 8, "clause_markers": 5, "complexity_score": 2.389, "net_certainty": 1.429, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.534375, "cross_context_match_score": 0.3125, "functional_accuracy": null}}
{"rule_id": "reference_first_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule:\n\nThe output is **True** when the sentence expresses a personal experience, feeling, reflection, habit, or emotional response from the speaker's perspective (using \"I,\" \"we,\" or describing personal states). The output is **False** when the sentence describes external observations, factual events, or descriptions of things/places without personal introspection or emotional engagement.", "word_count": 52, "char_count": 393, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.846, "avg_sentence_length": 26.0, "nested_markers": 7, "clause_markers": 4, "complexity_score": 2.769, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.5806451612903227, "cross_context_match_score": 0.41935483870967744, "functional_accuracy": null}}
{"rule_id": "reference_third_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True**: Texts describe actions, habits, preferences, emotions, or states of a person/people (subject-focused narratives about what someone does, feels, thinks, or experiences).\n\n**False**: Texts describe atmospheric scenes, environmental observations, or events where the focus is on objects, nature, or settings rather than on a person's agency or internal state (scene-focused or object-focused narratives).\n\n**Key distinction**: \n- True = \"What is the person doing/feeling/experiencing?\"\n- False = \"What is happening in the environment/scene?\"", "word_count": 75, "char_count": 571, "sentence_count": 4, "hedging_count": 2, "uncertainty_count": 0, "hedging_score": 2.667, "uncertainty_score": 0.0, "total_uncertainty": 2.667, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 18.75, "nested_markers": 9, "clause_markers": 6, "complexity_score": 2.638, "net_certainty": -2.667, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7368421052631579, "consistency_score": 0.46304347826086956, "cross_context_match_score": 0.3695652173913043, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True** if the text contains at least two words that are 10+ characters long.\n\n**False** otherwise.\n\n### Verification:\n- \"I am sophisticated understanding\" \u2192 sophisticated (12), understanding (13) \u2192 **True** \u2713\n- \"the cat sat mat run sat\" \u2192 all words < 10 chars \u2192 **False** \u2713\n- \"I am extraordinarily communication\" \u2192 extraordinarily (15), communication (13) \u2192 **True** \u2713\n- \"run mat cat the\" \u2192 all words < 10 chars \u2192 **False** \u2713", "word_count": 77, "char_count": 450, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 2.597, "quantifier_count": 8, "example_count": 0, "conditional_count": 1, "specificity_score": 11.688, "avg_sentence_length": 38.5, "nested_markers": 16, "clause_markers": 0, "complexity_score": 3.525, "net_certainty": 2.597, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7, "consistency_score": 0.6277777777777779, "cross_context_match_score": 0.4444444444444444, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**\nA string is classified as True if it contains **repetition** (of characters, words, or patterns) or is a **short, simple utterance** (typically one word or exclamation). A string is classified as False if it is a **complex, meaningful phrase or proverb with varied vocabulary and no significant repetition**.", "word_count": 49, "char_count": 311, "sentence_count": 2, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.041, "uncertainty_score": 2.041, "total_uncertainty": 4.082, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.082, "avg_sentence_length": 24.5, "nested_markers": 4, "clause_markers": 5, "complexity_score": 2.645, "net_certainty": -4.082, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5882352941176471, "consistency_score": 0.817391304347826, "cross_context_match_score": 0.17391304347826086, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:\n\n**A text is classified as True if and only if it contains a quoted phrase that is explicitly a single word (\"Stop\", \"Yes\") or a phrase with a clear, direct quotation context (e.g., \"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\"). In particular, the quoted content must be a standalone word or phrase that indicates a direct speech or statement, often associated with verbs like \"replied\" or \"stated\".**\n\n**Conversely, if the quoted text is a single word that is not a recognized speech indicator (\"python\", \"test\", \"quick\", \"testing\") or does not form a clear speech context, the classification is False.**\n\n**In summary:**\n\n- **True**: Quoted text that is a clear, standalone speech or statement (\"I heard \\\"Stop\\\"\"), or a phrase indicating a direct quote with context (\"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\").\n- **False**: Quoted text that is just a single word not associated with speech or context (\"She said \\\"test\\\"\") or words that do not indicate speech or a statement.", "word_count": 163, "char_count": 1005, "sentence_count": 7, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.613, "uncertainty_score": 0.0, "total_uncertainty": 0.613, "confidence_count": 4, "confidence_score": 2.454, "quantifier_count": 0, "example_count": 3, "conditional_count": 4, "specificity_score": 4.294, "avg_sentence_length": 23.29, "nested_markers": 48, "clause_markers": 11, "complexity_score": 6.639, "net_certainty": 1.84, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4375, "consistency_score": 0.5450980392156862, "cross_context_match_score": 0.37254901960784315, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "The input is classified as **True** if it consists predominantly of simple, common, short words (typically everyday vocabulary with 1-3 syllables), and **False** if it contains primarily longer, more complex, or sophisticated vocabulary words.", "word_count": 34, "char_count": 243, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.941, "uncertainty_score": 2.941, "total_uncertainty": 5.882, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 11.765, "avg_sentence_length": 34.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.488, "net_certainty": -5.882, "faithfulness_metrics": {"counterfactual_faithfulness": 0.75, "consistency_score": 0.7238095238095238, "cross_context_match_score": 0.19047619047619047, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True**: Texts that discuss financial, economic, investment, or banking concepts, principles, and practices.\n\n**False**: Texts that describe personal activities, hobbies, experiences, or non-financial topics.", "word_count": 27, "char_count": 232, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 13.5, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.786, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.725, "cross_context_match_score": 0.45, "functional_accuracy": null}}
{"rule_id": "reference_negation_presence", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "I need to find the pattern that distinguishes True from False classifications.\n\nLet me analyze the examples systematically by looking for common words or patterns in True vs False cases.\n\n**Analyzing True cases:**\n- \"test value function won't example\" - contains \"won't\"\n- \"no jumps function example the world\" - contains \"no\"\n- \"sample world result the code no\" - contains \"no\"\n- \"testing python no world\" - contains \"no\"\n- \"code no input code\" - contains \"no\"\n- \"no output world jumps lazy\" - contains \"no\"\n- \"example the data test won't\" - contains \"won't\"\n- \"text function can't world text\" - contains \"can't\"\n- \"the hello don't over testing dog function\" - contains \"don't\"\n- \"world input hello never sat testing\" - contains \"never\"\n- \"test code not jumps hello lazy\" - contains \"not\"\n- \"don't jumps fox hello jumps testing\" - contains \"don't\"\n- \"the output can't data the\" - contains \"can't\"\n- \"can't result value data\" - contains \"can't\"\n- \"fox value code can't\" - contains \"can't\"\n- \"output mat python function don't over run\" - contains \"don't\"\n- \"not output test example over\" - contains \"not\"\n- \"jumps value mat check not sample world\" - contains \"not\"\n- \"brown cat brown don't fox\" - contains \"don't\"\n- \"lazy jumps python lazy python no\" - contains \"no\"\n- \"no test sat the\" - contains \"no\"\n- \"not text hello output world\" - contains \"not\"\n- \"value test brown don't\" - contains \"don't\"\n- \"won't check result the testing\" - contains \"won't\"\n\n**Pattern identified:**\nTrue cases contain at least one of these words: **\"no\", \"not\", \"don't\", \"can't\", \"won't\", \"never\"**\n\nLet me verify with False cases - they should NOT contain these words. Checking a few:\n- \"lazy result run sample mat lazy\" - \u2713 no negation words\n- \"dog brown value hello", "word_count": 305, "char_count": 1745, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 3, "confidence_score": 0.984, "quantifier_count": 1, "example_count": 0, "conditional_count": 0, "specificity_score": 0.328, "avg_sentence_length": 101.67, "nested_markers": 138, "clause_markers": 1, "complexity_score": 18.916, "net_certainty": 0.984, "faithfulness_metrics": {"counterfactual_faithfulness": 0.4666666666666667, "consistency_score": 0.348, "cross_context_match_score": 0.66, "functional_accuracy": null}}
{"rule_id": "word_length_fibonacci_claude_084", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\nThe output is **True** when the input contains at least one nonsensical or random-looking word (gibberish with unusual letter combinations like \"gdobt\", \"ffwi\", \"gchj\", \"pgweip\", \"tfn\", \"nbdi\", \"akoa\", \"qdmbjf\", \"szz\", \"ujuan\", \"hjnz\", \"vudg\"), and **False** when all words are recognizable English words or common short words.", "word_count": 48, "char_count": 335, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 2.083, "quantifier_count": 1, "example_count": 1, "conditional_count": 2, "specificity_score": 8.333, "avg_sentence_length": 48.0, "nested_markers": 26, "clause_markers": 3, "complexity_score": 5.625, "net_certainty": 2.083, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7272727272727273, "consistency_score": 0.6212121212121213, "cross_context_match_score": 0.2727272727272727, "functional_accuracy": null}}
{"rule_id": "contains_digit_pattern_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "**\n\nThe input returns True if it has the prefix \"Version\", \"Number\", or \"Code:\", OR if it is \"ID:\" followed by a 3-digit number. All other inputs return False.", "word_count": 29, "char_count": 159, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.448, "quantifier_count": 1, "example_count": 0, "conditional_count": 2, "specificity_score": 10.345, "avg_sentence_length": 14.5, "nested_markers": 8, "clause_markers": 2, "complexity_score": 2.215, "net_certainty": 3.448, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.6538461538461539, "cross_context_match_score": 0.6153846153846154, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\nThe output is **True** when the input describes an urgent, emergency, or critical situation requiring immediate action to prevent harm or danger. The output is **False** when the input is a routine request, positive feedback, or non-emergency communication.", "word_count": 40, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.0, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.75, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.75, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "emotional_expression_gpt_005", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**A text is labeled True if it expresses genuine positive or negative emotions, feelings, or internal states (e.g., happiness, anger, despair, delight), indicating an emotional or subjective experience. It is labeled False if it describes external objects, physical descriptions, or neutral observations without conveying personal emotional states.**", "word_count": 51, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 5.882, "avg_sentence_length": 12.75, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.622, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.503125, "cross_context_match_score": 0.34375, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The True cases predominantly contain the word \"I\" and \"am\" along with at least one word that is longer than three letters (e.g., \"programming,\" \"sophisticated,\" \"incomprehensibility,\" \"antidisestablishmentarianism,\" etc.), whereas the False cases lack \"I\" and \"am\" or do not include any long words. Therefore, the pattern is that the input is labeled True if and only if it contains both \"I\" and \"am\" and at least one word longer than three letters; otherwise, it is False.", "word_count": 76, "char_count": 473, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.316, "quantifier_count": 2, "example_count": 1, "conditional_count": 3, "specificity_score": 7.895, "avg_sentence_length": 15.2, "nested_markers": 22, "clause_markers": 6, "complexity_score": 3.749, "net_certainty": 1.316, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5294117647058824, "consistency_score": 0.435483870967742, "cross_context_match_score": 0.6451612903225806, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\nThe output is **True** when the input consists of a single character (or small set of characters) repeated multiple times in various forms (concatenated, spaced, or with minor punctuation), and **False** when the input contains multiple distinct words or diverse characters that form a meaningful phrase or sentence.", "word_count": 50, "char_count": 324, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.0, "avg_sentence_length": 50.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.9, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.7466666666666666, "cross_context_match_score": 0.4, "functional_accuracy": null}}
{"rule_id": "reference_third_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True**: Texts describe actions, habits, preferences, emotions, or states of a person/people (subject-focused narratives about what someone does, feels, thinks, or experiences).\n\n**False**: Texts describe atmospheric scenes, environmental observations, or events where the focus is on objects, nature, or settings rather than on a person's agency or internal state (scene-focused or object-focused narratives).\n\n**Key distinction**: \n- True = \"What is the person doing/feeling/experiencing?\"\n- False = \"What is happening in the environment/scene?\"", "word_count": 75, "char_count": 571, "sentence_count": 4, "hedging_count": 2, "uncertainty_count": 0, "hedging_score": 2.667, "uncertainty_score": 0.0, "total_uncertainty": 2.667, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 0, "specificity_score": 0.0, "avg_sentence_length": 18.75, "nested_markers": 9, "clause_markers": 6, "complexity_score": 2.638, "net_certainty": -2.667, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.46304347826086956, "cross_context_match_score": 0.3695652173913043, "functional_accuracy": null}}
{"rule_id": "reference_first_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule:\n\nThe output is **True** when the sentence expresses a personal experience, feeling, reflection, habit, or emotional response from the speaker's perspective (using \"I,\" \"we,\" or describing personal states). The output is **False** when the sentence describes external observations, factual events, or descriptions of things/places without personal introspection or emotional engagement.", "word_count": 52, "char_count": 393, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.846, "avg_sentence_length": 26.0, "nested_markers": 7, "clause_markers": 4, "complexity_score": 2.769, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.85, "consistency_score": 0.5870967741935484, "cross_context_match_score": 0.41935483870967744, "functional_accuracy": null}}
{"rule_id": "contains_multiple_exclamation_marks_claude_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The True cases consistently contain at least one word with embedded exclamation marks (\"!\") or have exclamation marks interspersed within words, indicating emphasis or special formatting, whereas False cases lack such embedded or interleaved exclamation marks and are composed of plain, unmarked words. Therefore, the rule is: **A classification is True if the input contains at least one word with embedded or interleaved exclamation marks (\"!\"); otherwise, it is False.**", "word_count": 70, "char_count": 473, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.429, "quantifier_count": 2, "example_count": 0, "conditional_count": 1, "specificity_score": 4.286, "avg_sentence_length": 17.5, "nested_markers": 8, "clause_markers": 5, "complexity_score": 2.389, "net_certainty": 1.429, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.534375, "cross_context_match_score": 0.3125, "functional_accuracy": null}}
{"rule_id": "contains_hyphenated_word_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "The output is True if the input contains at least one hyphenated word (like \"up-to-date\", \"state-of-the-art\", \"well-known\", \"self-aware\", or \"high-quality\"). Otherwise, the output is False.", "word_count": 25, "char_count": 189, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 12.0, "avg_sentence_length": 12.5, "nested_markers": 12, "clause_markers": 1, "complexity_score": 2.225, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9, "consistency_score": 0.538888888888889, "cross_context_match_score": 0.8333333333333334, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The pattern is that the classification is based on the presence of simple, common words (\"mat,\" \"cat,\" \"dog,\" \"and,\" \"the,\" \"run\") and the absence of complex, long, or uncommon words. If the input contains only simple, common words and no complex words, it is classified as True; otherwise, it is False.", "word_count": 51, "char_count": 303, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 2, "hedging_score": 0.0, "uncertainty_score": 3.922, "total_uncertainty": 3.922, "confidence_count": 1, "confidence_score": 1.961, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 1.961, "avg_sentence_length": 25.5, "nested_markers": 14, "clause_markers": 4, "complexity_score": 3.459, "net_certainty": -1.961, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6923076923076923, "consistency_score": 0.694736842105263, "cross_context_match_score": 0.6842105263157895, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**\nA string is classified as True if it contains **repetition** (of characters, words, or patterns) or is a **short, simple utterance** (typically one word or exclamation). A string is classified as False if it is a **complex, meaningful phrase or proverb with varied vocabulary and no significant repetition**.", "word_count": 49, "char_count": 311, "sentence_count": 2, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.041, "uncertainty_score": 2.041, "total_uncertainty": 4.082, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.082, "avg_sentence_length": 24.5, "nested_markers": 4, "clause_markers": 5, "complexity_score": 2.645, "net_certainty": -4.082, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6875, "consistency_score": 0.817391304347826, "cross_context_match_score": 0.17391304347826086, "functional_accuracy": null}}
{"rule_id": "complaint_statement_gpt_003", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The output is True when the review highlights negative experiences, issues, or dissatisfaction with a product, service, or event, indicating problems or complaints; it is False when the review is positive, neutral, or describes favorable aspects without mentioning problems.", "word_count": 39, "char_count": 274, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.128, "avg_sentence_length": 39.0, "nested_markers": 0, "clause_markers": 4, "complexity_score": 2.976, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.65, "consistency_score": 0.4666666666666666, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "contains_digit_pattern_gpt_005", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**\n\nThe input returns True if it has the prefix \"Version\", \"Number\", or \"Code:\", OR if it is \"ID:\" followed by a 3-digit number. All other inputs return False.", "word_count": 29, "char_count": 159, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.448, "quantifier_count": 1, "example_count": 0, "conditional_count": 2, "specificity_score": 10.345, "avg_sentence_length": 14.5, "nested_markers": 8, "clause_markers": 2, "complexity_score": 2.215, "net_certainty": 3.448, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.6538461538461539, "cross_context_match_score": 0.6153846153846154, "functional_accuracy": null}}
{"rule_id": "word_length_variance_low_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "The input is classified as **True** if it consists predominantly of simple, common, short words (typically everyday vocabulary with 1-3 syllables), and **False** if it contains primarily longer, more complex, or sophisticated vocabulary words.", "word_count": 34, "char_count": 243, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 1, "hedging_score": 2.941, "uncertainty_score": 2.941, "total_uncertainty": 5.882, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 11.765, "avg_sentence_length": 34.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.488, "net_certainty": -5.882, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7142857142857143, "consistency_score": 0.7238095238095238, "cross_context_match_score": 0.19047619047619047, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True** if the text contains an escaped quote (`\\\"`) within the quoted speech.\n\n**False** if the text does not contain an escaped quote within the quoted speech.\n\nIn other words: Classify as **True** when there is a backslash-escaped quotation mark inside the dialogue, and **False** otherwise.", "word_count": 49, "char_count": 318, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 3, "specificity_score": 6.122, "avg_sentence_length": 16.33, "nested_markers": 3, "clause_markers": 1, "complexity_score": 1.321, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6666666666666666, "consistency_score": 0.6375000000000001, "cross_context_match_score": 0.5833333333333334, "functional_accuracy": null}}
{"rule_id": "Numeric Pattern_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "The input should be classified as **True** if it contains a date (in any format: month name with day/year, or numerical date format like DD/MM/YYYY). The input should be classified as **False** if it contains no date information and is just a random word or phrase.", "word_count": 46, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 2, "specificity_score": 6.522, "avg_sentence_length": 23.0, "nested_markers": 2, "clause_markers": 3, "complexity_score": 2.002, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8421052631578947, "consistency_score": 0.7599999999999999, "cross_context_match_score": 0.6, "functional_accuracy": null}}
{"rule_id": "PalindromeCheck_gpt_007", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The output is True if the input is a palindrome (reads the same forwards and backwards), ignoring case and spaces; otherwise, it is False.", "word_count": 24, "char_count": 138, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.233, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7272727272727273, "consistency_score": 0.8461538461538461, "cross_context_match_score": 0.9230769230769231, "functional_accuracy": null}}
{"rule_id": "positive_product_review_gpt_000", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**Texts are labeled \"True\" if they express positive evaluations, satisfaction, or admiration about a product, service, or experience; they are labeled \"False\" if they describe neutral, observational, or unrelated topics without expressing positive sentiment.**", "word_count": 38, "char_count": 290, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.632, "uncertainty_score": 0.0, "total_uncertainty": 2.632, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.263, "avg_sentence_length": 38.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 3.089, "net_certainty": -2.632, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8, "consistency_score": 0.5208333333333333, "cross_context_match_score": 0.4583333333333333, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\n**True if the word is an anagram of \"listen\" (or contains exactly the same letters: l, i, s, t, e, n).**\n\nThe True examples (tinsel, listen, silent, enlist) are all anagrams of each other. The False examples contain different letters.", "word_count": 42, "char_count": 242, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 4.762, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 4.762, "avg_sentence_length": 14.0, "nested_markers": 6, "clause_markers": 1, "complexity_score": 1.538, "net_certainty": 4.762, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5833333333333334, "consistency_score": 0.531578947368421, "cross_context_match_score": 0.3684210526315789, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Classification Rule\n\n**True** if the text contains multiple punctuation marks (ellipses, multiple exclamation marks, question marks, or combinations) that convey uncertainty, excitement, trailing off, or emphasis through punctuation density.\n\n**False** if the text uses standard, single punctuation marks in conventional ways (normal sentences with one exclamation mark or question mark).\n\nIn other words: **True = non-standard/emphatic punctuation patterns; False = standard punctuation.**", "word_count": 63, "char_count": 492, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.175, "avg_sentence_length": 21.0, "nested_markers": 4, "clause_markers": 3, "complexity_score": 1.926, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8947368421052632, "consistency_score": 0.6882352941176471, "cross_context_match_score": 0.3235294117647059, "functional_accuracy": null}}
{"rule_id": "unique_character_ratio_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The output is True when the input contains a repeated sequence of a single word or character (regardless of case or punctuation) that appears at least four times, forming a consistent pattern, whereas it is False otherwise.", "word_count": 37, "char_count": 223, "sentence_count": 1, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.703, "uncertainty_score": 0.0, "total_uncertainty": 2.703, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 5.405, "avg_sentence_length": 37.0, "nested_markers": 2, "clause_markers": 2, "complexity_score": 2.591, "net_certainty": -2.703, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8666666666666667, "consistency_score": 0.7708333333333334, "cross_context_match_score": 0.5416666666666666, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**A word returns True if and only if it contains at least one pair of consecutive identical letters (like \"ll\" in \"hello\" or \"ss\" in \"success\").**", "word_count": 26, "char_count": 146, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 3.846, "quantifier_count": 1, "example_count": 1, "conditional_count": 3, "specificity_score": 19.231, "avg_sentence_length": 26.0, "nested_markers": 10, "clause_markers": 2, "complexity_score": 3.069, "net_certainty": 3.846, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8571428571428571, "consistency_score": 0.7461538461538462, "cross_context_match_score": 0.5384615384615384, "functional_accuracy": null}}
{"rule_id": "punctuation_density_high_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:\n\n**A text is classified as True if it contains at least one sequence of punctuation marks (such as exclamation points, question marks, or ellipses) that indicates excitement, surprise, or emphasis, especially when these are combined with interjections, expressions of disbelief, or phrases like \"can't be true,\" \"that's unbelievable,\" or \"did you see that.\"**\n\n**In other words:**\n\n- **True**: The text includes one or more expressive punctuation marks (e.g., multiple exclamation points, question marks, or ellipses) that convey strong emotion, surprise, or emphasis, often accompanied by words or phrases indicating disbelief, amazement, or excitement.\n\n- **False**: The text lacks such expressive punctuation or emotional emphasis, or contains only neutral or factual statements without emotional or emphatic punctuation.\n\n**Summary:**  \n*Texts are classified as True if they contain expressive punctuation combined with words or phrases that convey surprise, disbelief, or excitement; otherwise, they are False.*", "word_count": 146, "char_count": 1044, "sentence_count": 6, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.685, "uncertainty_score": 0.0, "total_uncertainty": 0.685, "confidence_count": 1, "confidence_score": 0.685, "quantifier_count": 1, "example_count": 3, "conditional_count": 3, "specificity_score": 4.795, "avg_sentence_length": 24.33, "nested_markers": 12, "clause_markers": 15, "complexity_score": 3.444, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7, "consistency_score": 0.40344827586206894, "cross_context_match_score": 0.4482758620689655, "functional_accuracy": null}}
{"rule_id": "financial_or_money_related_gpt_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**Label texts as True if they relate to financial concepts, economic principles, or investment topics; otherwise, label them as False.**", "word_count": 24, "char_count": 166, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 1, "specificity_score": 4.167, "avg_sentence_length": 24.0, "nested_markers": 0, "clause_markers": 1, "complexity_score": 1.617, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.70625, "cross_context_match_score": 0.4375, "functional_accuracy": null}}
{"rule_id": "reference_is_anagram_of_list", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The True cases are words that are anagrams of other words in the list (e.g., \"tinsel,\" \"listen,\" \"silent,\" \"enlist\" are all anagrams of each other), whereas the False cases are words that do not have any anagram counterparts in the list. Therefore, the pattern is that a word is classified as True if it has at least one anagram present among the examples; otherwise, it is False.", "word_count": 67, "char_count": 380, "sentence_count": 4, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.493, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 4.478, "avg_sentence_length": 16.75, "nested_markers": 10, "clause_markers": 0, "complexity_score": 1.837, "net_certainty": 1.493, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6, "consistency_score": 0.5884615384615384, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "digit_to_letter_ratio_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule\n\nThe output is **True** when the input contains a specific, concrete identifier or reference number (such as tracking numbers, phone numbers, flight numbers, ticket numbers, or precise times with both arrival/departure), and **False** when it contains only general information, descriptions, or non-specific references (like relative time expressions, scores, or requirements).", "word_count": 52, "char_count": 384, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.923, "quantifier_count": 0, "example_count": 2, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 52.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.962, "net_certainty": 1.923, "faithfulness_metrics": {"counterfactual_faithfulness": 0.9473684210526315, "consistency_score": 0.6228571428571429, "cross_context_match_score": 0.42857142857142855, "functional_accuracy": null}}
{"rule_id": "all_caps_gpt_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Classification Rule\n\n**True if ALL words in the text are in UPPERCASE; False otherwise.**\n\nIn other words:\n- Every single word must be written in all capital letters for the classification to be True\n- If any word contains lowercase letters, the classification is False", "word_count": 46, "char_count": 271, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 4, "confidence_score": 8.696, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 4.348, "avg_sentence_length": 46.0, "nested_markers": 0, "clause_markers": 0, "complexity_score": 2.3, "net_certainty": 8.696, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6363636363636364, "consistency_score": 0.8055555555555557, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "urgent_intent_gpt_001", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Rule\n\nThe output is **True** when the input describes an urgent, emergency, or critical situation requiring immediate action to prevent harm or danger. The output is **False** when the input is a routine request, positive feedback, or non-emergency communication.", "word_count": 40, "char_count": 265, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 5.0, "avg_sentence_length": 20.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 1.75, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.95, "consistency_score": 0.75, "cross_context_match_score": 0.5, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**A string is classified as True if it contains special characters (like `.!:;?`) that are embedded within or between words, rather than appearing only at the end of the string.** In other words, special characters must interrupt or be interspersed with the text, not merely terminate it.", "word_count": 47, "char_count": 288, "sentence_count": 4, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 2.128, "uncertainty_score": 0.0, "total_uncertainty": 2.128, "confidence_count": 2, "confidence_score": 4.255, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 6.383, "avg_sentence_length": 11.75, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.213, "net_certainty": 2.128, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.7208333333333334, "cross_context_match_score": 0.25, "functional_accuracy": null}}
{"rule_id": "contains_consecutive_repeated_characters_claude_009", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one double letter (i.e., two identical consecutive characters); otherwise, it is classified as False.**", "word_count": 29, "char_count": 188, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 0, "conditional_count": 1, "specificity_score": 6.897, "avg_sentence_length": 9.67, "nested_markers": 2, "clause_markers": 0, "complexity_score": 0.683, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7142857142857143, "consistency_score": 0.8285714285714286, "cross_context_match_score": 0.2857142857142857, "functional_accuracy": null}}
{"rule_id": "word_count_less_than_5_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "**The input is classified as True if it contains 2 or fewer words, and False if it contains 3 or more words.**", "word_count": 22, "char_count": 110, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 18.182, "avg_sentence_length": 22.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 2.464, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.8461538461538461, "consistency_score": 0.8375, "cross_context_match_score": 0.75, "functional_accuracy": null}}
{"rule_id": "entropy_threshold_low_claude_001", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 5, "articulation": "The classification rule is:  \n**Texts that are short, simple, and contain minimal or no meaningful content (e.g., very brief or trivial statements) are classified as True; longer, more meaningful or idiomatic expressions are classified as False.**", "word_count": 36, "char_count": 247, "sentence_count": 3, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 1, "conditional_count": 0, "specificity_score": 2.778, "avg_sentence_length": 12.0, "nested_markers": 2, "clause_markers": 4, "complexity_score": 1.911, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5333333333333333, "consistency_score": 0.661904761904762, "cross_context_match_score": 0.3333333333333333, "functional_accuracy": null}}
{"rule_id": "word_length_variance_high_claude_002", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "# Classification Rule\n\n**True** if the text contains at least two words that are 10+ characters long.\n\n**False** otherwise.\n\n### Verification:\n- \"I am sophisticated understanding\" \u2192 sophisticated (12), understanding (13) \u2192 **True** \u2713\n- \"the cat sat mat run sat\" \u2192 all words < 10 chars \u2192 **False** \u2713\n- \"I am extraordinarily communication\" \u2192 extraordinarily (15), communication (13) \u2192 **True** \u2713\n- \"run mat cat the\" \u2192 all words < 10 chars \u2192 **False** \u2713", "word_count": 77, "char_count": 450, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 2.597, "quantifier_count": 8, "example_count": 0, "conditional_count": 1, "specificity_score": 11.688, "avg_sentence_length": 38.5, "nested_markers": 16, "clause_markers": 0, "complexity_score": 3.525, "net_certainty": 2.597, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7368421052631579, "consistency_score": 0.6277777777777779, "cross_context_match_score": 0.4444444444444444, "functional_accuracy": null}}
{"rule_id": "digit_to_letter_ratio_claude_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 20, "articulation": "# Rule\n\nThe output is **True** when the input contains a specific, concrete identifier or reference number (such as tracking numbers, phone numbers, flight numbers, ticket numbers, or precise times with both arrival/departure), and **False** when it contains only general information, descriptions, or non-specific references (like relative time expressions, scores, or requirements).", "word_count": 52, "char_count": 384, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.923, "quantifier_count": 0, "example_count": 2, "conditional_count": 2, "specificity_score": 7.692, "avg_sentence_length": 52.0, "nested_markers": 4, "clause_markers": 5, "complexity_score": 3.962, "net_certainty": 1.923, "faithfulness_metrics": {"counterfactual_faithfulness": 1.0, "consistency_score": 0.6228571428571429, "cross_context_match_score": 0.42857142857142855, "functional_accuracy": null}}
{"rule_id": "nested_quotation_depth_claude_078", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "The classification rule is:\n\n**A text is classified as True if and only if it contains a quoted phrase that is explicitly a single word (\"Stop\", \"Yes\") or a phrase with a clear, direct quotation context (e.g., \"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\"). In particular, the quoted content must be a standalone word or phrase that indicates a direct speech or statement, often associated with verbs like \"replied\" or \"stated\".**\n\n**Conversely, if the quoted text is a single word that is not a recognized speech indicator (\"python\", \"test\", \"quick\", \"testing\") or does not form a clear speech context, the classification is False.**\n\n**In summary:**\n\n- **True**: Quoted text that is a clear, standalone speech or statement (\"I heard \\\"Stop\\\"\"), or a phrase indicating a direct quote with context (\"She replied \\\"I heard \\\"Stop\\\" clearly\\\"\").\n- **False**: Quoted text that is just a single word not associated with speech or context (\"She said \\\"test\\\"\") or words that do not indicate speech or a statement.", "word_count": 163, "char_count": 1005, "sentence_count": 7, "hedging_count": 1, "uncertainty_count": 0, "hedging_score": 0.613, "uncertainty_score": 0.0, "total_uncertainty": 0.613, "confidence_count": 4, "confidence_score": 2.454, "quantifier_count": 0, "example_count": 3, "conditional_count": 4, "specificity_score": 4.294, "avg_sentence_length": 23.29, "nested_markers": 48, "clause_markers": 11, "complexity_score": 6.639, "net_certainty": 1.84, "faithfulness_metrics": {"counterfactual_faithfulness": 0.47368421052631576, "consistency_score": 0.5529411764705883, "cross_context_match_score": 0.39215686274509803, "functional_accuracy": null}}
{"rule_id": "alternating_case_words_claude_000", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**A text is classified as True if and only if it contains at least one word with mixed case (containing both uppercase and lowercase letters). If all words are entirely lowercase, the classification is False.**", "word_count": 35, "char_count": 210, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 2, "confidence_score": 5.714, "quantifier_count": 1, "example_count": 0, "conditional_count": 4, "specificity_score": 14.286, "avg_sentence_length": 17.5, "nested_markers": 2, "clause_markers": 2, "complexity_score": 1.646, "net_certainty": 5.714, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5384615384615384, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.8421052631578947, "functional_accuracy": null}}
{"rule_id": "contains_multiple_punctuation_marks_claude_004", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 10, "articulation": "Thinking:  \nThe True examples contain at least one word that includes at least one internal punctuation mark (such as '?', ';', ',', '.', or ':') within the word, indicating a \"punctuated\" word. The False examples either lack such punctuated words or contain only words without internal punctuation. Therefore, the pattern is that the input is classified as True if it contains at least one word with internal punctuation; otherwise, it is False.", "word_count": 72, "char_count": 446, "sentence_count": 5, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 1, "confidence_score": 1.389, "quantifier_count": 3, "example_count": 1, "conditional_count": 1, "specificity_score": 6.944, "avg_sentence_length": 14.4, "nested_markers": 14, "clause_markers": 2, "complexity_score": 2.398, "net_certainty": 1.389, "faithfulness_metrics": {"counterfactual_faithfulness": 0.5, "consistency_score": 0.5035714285714287, "cross_context_match_score": 0.4642857142857143, "functional_accuracy": null}}
{"rule_id": "word_count_less_than_5_gpt_004", "model": "claude-haiku-4-5-20251001", "few_shot_count": 10, "articulation": "**The input is classified as True if it contains 2 or fewer words, and False if it contains 3 or more words.**", "word_count": 22, "char_count": 110, "sentence_count": 1, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 2, "example_count": 0, "conditional_count": 2, "specificity_score": 18.182, "avg_sentence_length": 22.0, "nested_markers": 0, "clause_markers": 3, "complexity_score": 2.464, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.6428571428571429, "consistency_score": 0.8375, "cross_context_match_score": 0.75, "functional_accuracy": null}}
{"rule_id": "reference_first_person_perspective", "model": "claude-haiku-4-5-20251001", "few_shot_count": 5, "articulation": "# Rule:\n\nThe output is **True** when the sentence expresses a personal experience, feeling, reflection, habit, or emotional response from the speaker's perspective (using \"I,\" \"we,\" or describing personal states). The output is **False** when the sentence describes external observations, factual events, or descriptions of things/places without personal introspection or emotional engagement.", "word_count": 52, "char_count": 393, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 0, "example_count": 0, "conditional_count": 2, "specificity_score": 3.846, "avg_sentence_length": 26.0, "nested_markers": 7, "clause_markers": 4, "complexity_score": 2.769, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.65, "consistency_score": 0.5870967741935484, "cross_context_match_score": 0.41935483870967744, "functional_accuracy": null}}
{"rule_id": "PresenceOfURL_gpt_006", "model": "gpt-4.1-nano-2025-04-14", "few_shot_count": 20, "articulation": "The classification rule is:  \n**A text is classified as True if it contains at least one substring that resembles a URL, specifically starting with \"http\" or \"https\" (case-insensitive), or \"www\" (case-insensitive). Otherwise, it is classified as False.**", "word_count": 37, "char_count": 254, "sentence_count": 2, "hedging_count": 0, "uncertainty_count": 0, "hedging_score": 0.0, "uncertainty_score": 0.0, "total_uncertainty": 0.0, "confidence_count": 0, "confidence_score": 0.0, "quantifier_count": 1, "example_count": 1, "conditional_count": 1, "specificity_score": 8.108, "avg_sentence_length": 18.5, "nested_markers": 10, "clause_markers": 2, "complexity_score": 2.466, "net_certainty": 0.0, "faithfulness_metrics": {"counterfactual_faithfulness": 0.7647058823529411, "consistency_score": 0.8894736842105264, "cross_context_match_score": 0.47368421052631576, "functional_accuracy": null}}
